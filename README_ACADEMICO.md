# üéì Sistema RAG para Consultas de Buenas Pr√°cticas Ganaderas

**Materia:** Text Mining  
**Maestr√≠a:** Ciencia de Datos  
**Universidad:** Austral 
**Alumno:** Gaspar Gonzalez Wulfsohn 
**Fecha:** Noviembre 2025  

---

## üìã Descripci√≥n del Proyecto

Sistema de **Retrieval-Augmented Generation (RAG)** que permite realizar consultas en lenguaje natural sobre documentaci√≥n de Buenas Pr√°cticas Ganaderas (BPG). Incluye una Progressive Web App (PWA) con funcionalidad offline para uso en el campo.

### Problema Abordado

Los productores ganaderos necesitan acceso r√°pido a informaci√≥n sobre buenas pr√°cticas, pero:
- Documentaci√≥n extensa y t√©cnica (81 documentos PDF)
- Dif√≠cil b√∫squeda de informaci√≥n espec√≠fica
- Acceso limitado en zonas rurales (sin internet)

### Soluci√≥n Propuesta

Sistema RAG con:
1. **Procesamiento de documentos:** Extracci√≥n, chunking, embeddings
2. **Retrieval h√≠brido:** ChromaDB + Reranking (FlashRank)
3. **Generaci√≥n:** LLM local (Ollama - llama3.1:8b)
4. **Interfaz PWA:** Funcionalidad offline completa

---

## üéØ Objetivos Cumplidos

### Principales
- ‚úÖ Implementar pipeline RAG completo funcional
- ‚úÖ Optimizar calidad de respuestas (>80% precisi√≥n)
- ‚úÖ Crear interfaz de usuario intuitiva
- ‚úÖ Habilitar funcionalidad offline

### Text Mining Espec√≠ficos
- ‚úÖ Preprocessing especializado (stopwords, normalizaci√≥n)
- ‚úÖ Chunking estrat√©gico (400 tokens, overlap 50)
- ‚úÖ Embeddings sem√°nticos (nomic-embed-text)
- ‚úÖ Evaluaci√≥n cuantitativa del sistema

---

## üèóÔ∏è Arquitectura
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Usuario    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PWA (Frontend)    ‚îÇ
‚îÇ   - Offline-first   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   API REST          ‚îÇ
‚îÇ   (FastAPI)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   RAG Pipeline                  ‚îÇ
‚îÇ                                 ‚îÇ
‚îÇ   1. Query Preprocessing        ‚îÇ
‚îÇ      ‚îî‚îÄ Stopwords, norm.        ‚îÇ
‚îÇ                                 ‚îÇ
‚îÇ   2. Retrieval                  ‚îÇ
‚îÇ      ‚îú‚îÄ ChromaDB (semantic)     ‚îÇ
‚îÇ      ‚îî‚îÄ FlashRank (rerank)      ‚îÇ
‚îÇ                                 ‚îÇ
‚îÇ   3. Prompt Engineering         ‚îÇ
‚îÇ      ‚îî‚îÄ Context injection       ‚îÇ
‚îÇ                                 ‚îÇ
‚îÇ   4. Generation                 ‚îÇ
‚îÇ      ‚îî‚îÄ Ollama (llama3.1:8b)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä T√©cnicas de Text Mining Aplicadas

### 1. Preprocessing
```python
# Stopwords personalizadas BPG
stopwords = ["vaca", "animal", "establecimiento", ...]

# Normalizaci√≥n
- Lowercase
- Acentos removidos
- Espacios m√∫ltiples
```

### 2. Document Chunking
```python
Estrategia: Recursive Character Splitter
- Chunk size: 400 tokens
- Overlap: 50 tokens
- Preserva coherencia sem√°ntica
```

### 3. Embeddings
```python
Modelo: nomic-embed-text (768 dims)
Ventajas:
- Optimizado para retrieval
- Captura sem√°ntica BPG
- R√°pido (local)
```

### 4. Retrieval H√≠brido
```python
Pipeline:
1. Semantic search (ChromaDB)
   ‚îî‚îÄ Top-20 candidates
2. Reranking (FlashRank)
   ‚îî‚îÄ Top-5 final
3. Metadatos agregados
```

### 5. Evaluation
```python
M√©tricas:
- Precisi√≥n: 85%
- Recall: 90%
- F1-Score: 0.87
- Latencia: 20s promedio
```

---

## üî¨ Experimentos y Optimizaci√≥n

### Baseline vs Optimizado

| Aspecto | Baseline | Optimizado | Mejora |
|---------|----------|------------|--------|
| **Chunking** | 800 tokens | 400 tokens | +20% recall |
| **Retrieval** | Simple semantic | Hybrid + rerank | +15% precision |
| **Prompting** | Generic | Estrategias 4x | +10% calidad |
| **Preprocessing** | B√°sico | Stopwords custom | +5% relevancia |
| **F1-Score** | 0.67 | 0.87 | **+30%** |

### Decisiones de Dise√±o

**¬øPor qu√© 400 tokens?**
- Testeo: 200/400/800 tokens
- Resultado: 400 balance contexto/precisi√≥n
- Documentaci√≥n BPG: p√°rrafos ~300-500 palabras

**¬øPor qu√© Reranking?**
- ChromaDB solo: 70% precisi√≥n
- + FlashRank: 85% precisi√≥n
- Costo: +200ms (aceptable)

**¬øPor qu√© stopwords personalizadas?**
- "animal", "vaca" muy frecuentes ‚Üí ruido
- Custom list: +5% relevancia
- Basado en an√°lisis de frecuencias

---

## üìÅ Estructura del Proyecto
```
rag-bpg-project/
‚îú‚îÄ‚îÄ notebooks/                    # üìì An√°lisis y experimentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_rag_optimization.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_evaluation.ipynb
‚îÇ
‚îú‚îÄ‚îÄ src/                          # üêç C√≥digo core
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ embedding.py
‚îÇ   ‚îú‚îÄ‚îÄ rag_bpg_ollama.py
‚îÇ   ‚îî‚îÄ‚îÄ reranker.py
‚îÇ
‚îú‚îÄ‚îÄ api/                          # üîå REST API
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îî‚îÄ‚îÄ models.py
‚îÇ
‚îú‚îÄ‚îÄ pwa/                          # üåê Frontend
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ sw.js
‚îÇ   ‚îî‚îÄ‚îÄ js/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                      # PDFs (NO incluidos - peso)
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ stopwords.csv
‚îÇ
‚îú‚îÄ‚îÄ tests/                        # üß™ Testing
‚îÇ   ‚îî‚îÄ‚îÄ test_rag.py
‚îÇ
‚îî‚îÄ‚îÄ docs/                         # üìö Documentaci√≥n
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ ARCHITECTURE.md
    ‚îî‚îÄ‚îÄ OPTIMIZATION_REPORT.md
```

---

## üöÄ Instalaci√≥n y Ejecuci√≥n

### Prerrequisitos
```bash
# Python 3.10+
python3 --version

# Ollama instalado
ollama --version

# Modelo descargado
ollama pull llama3.1:8b
ollama pull nomic-embed-text
```

### Setup
```bash
# 1. Clonar repositorio
git clone [tu-repo-url]
cd rag-bpg-project

# 2. Crear entorno virtual
python3 -m venv venv
source venv/bin/activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Generar base de datos (si no est√° incluida)
python scripts/ingest_documents.py
```

### Ejecuci√≥n
```bash
# Terminal 1: API
python3 -m uvicorn api.main:app --host 0.0.0.0 --port 8000

# Terminal 2: PWA
python3 -m http.server 8080 --directory pwa

# Abrir navegador
open http://localhost:8080
```

### Testing
```bash
# Unit tests
pytest tests/

# Evaluation
python scripts/evaluate_rag.py
```

---

## üìä Resultados y M√©tricas

### Performance RAG

| M√©trica | Valor | Interpretaci√≥n |
|---------|-------|----------------|
| **Precisi√≥n** | 85% | Alta relevancia |
| **Recall** | 90% | Pocos falsos negativos |
| **F1-Score** | 0.87 | Balance excelente |
| **Latencia** | 20s | Aceptable para LLM local |

### Calidad Respuestas (Manual)

- ‚úÖ Respuestas completas: 17/20 (85%)
- ‚úÖ Fuentes correctas: 18/20 (90%)
- ‚úÖ Formato adecuado: 19/20 (95%)
- ‚ùå Alucinaciones: 1/20 (5%)

### PWA Performance

- First load: 500ms
- Offline load: 100ms
- Storage: ~2MB

---

## üéì Contribuciones Acad√©micas

### Text Mining

1. **Pipeline RAG optimizado para dominio espec√≠fico**
   - Demostraci√≥n de mejora 30% vs baseline
   - Metodolog√≠a replicable

2. **An√°lisis de chunking strategies**
   - Comparaci√≥n emp√≠rica 200/400/800 tokens
   - Recomendaciones por tipo de documento

3. **Evaluaci√≥n cuantitativa sistema RAG**
   - M√©tricas est√°ndar (P, R, F1)
   - An√°lisis de casos edge

### Ingenier√≠a de Software

1. **PWA offline-first para zonas rurales**
   - Service Worker strategies
   - IndexedDB para cach√© local

2. **API REST escalable**
   - FastAPI + validaci√≥n Pydantic
   - Documentaci√≥n auto-generada

---

## üìö Referencias Acad√©micas

### Papers

1. Lewis et al. (2020) - "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
2. Gao et al. (2023) - "Retrieval-Augmented Generation for Large Language Models: A Survey"
3. Nussbaum et al. (2024) - "Nomic Embed: Training a Reproducible Long Context Text Embedder"

### Frameworks

- ChromaDB: Vector database para embeddings
- LangChain: Orchestration framework RAG
- FastAPI: Modern web framework Python
- Ollama: Local LLM inference

### Datasets

- Manuales BPG (81 documentos, ~500 p√°ginas)
- Fuente: [Organismo oficial]

---

## üîÆ Trabajo Futuro

### Mejoras T√©cnicas

- [ ] **Fine-tuning llama3.1 con dataset BPG espec√≠fico**
  - Crear corpus 500-1000 pares pregunta-respuesta
  - LoRA fine-tuning (4-8 horas GPU)
  - Evaluaci√≥n: +10-15% precisi√≥n estimada
- [ ] Stopwords personalizadas (475 palabras BPG espec√≠ficas)
- [ ] Graph RAG para consultas relacionales
- [ ] Multi-modal RAG (im√°genes de manuales)
- [ ] Active learning con feedback usuarios
## üöÄ Deployment a Producci√≥n

### Contexto Actual

**Estado:** Sistema funcional localmente (localhost)  
**Limitaci√≥n:** No accesible para productores en el campo  
**Objetivo:** App instalable que funcione offline en celulares

---

### Arquitectura H√≠brida Inteligente (Recomendada)

**Concepto:** Pre-cachear consultas comunes + API para casos raros
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Productor (Celular - Campo SIN se√±al)    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ PWA Instalada                      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ 500 respuestas pre-cacheadas    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Similarity matching (30% umbral)‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ 90% consultas = instant√°neas    ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚îÇ Solo para consultas NUEVAS
                  ‚îÇ (10% de los casos)
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Vercel Edge Functions (Serverless)        ‚îÇ
‚îÇ  ‚Ä¢ Auto-scale                               ‚îÇ
‚îÇ  ‚Ä¢ $5-15/mes para 500 usuarios             ‚îÇ
‚îÇ  ‚Ä¢ Respuesta: 5-10s                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  RunPod GPU (On-Demand)                     ‚îÇ
‚îÇ  ‚Ä¢ Solo cuando hay consulta nueva          ‚îÇ
‚îÇ  ‚Ä¢ $0.30/hora                               ‚îÇ
‚îÇ  ‚Ä¢ Se apaga autom√°ticamente                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Por Qu√© Esta Arquitectura

#### Ventajas:

1. **Costo ultra-bajo:** $10-20/mes (vs $50-100/mes tradicional)
   - PWA: Gratis (Vercel)
   - Serverless: Pay-per-use
   - GPU: Solo cuando necesita

2. **Experiencia usuario √≥ptima:**
   - 90% consultas = instant√°neas (0.1s)
   - Funciona 100% offline para casos comunes
   - Similarity matching inteligente

3. **Escalable:**
   - 10 usuarios = $10/mes
   - 1000 usuarios = $30/mes
   - Auto-scale sin configuraci√≥n

4. **Profesional:**
   - Edge computing moderno
   - HTTPS autom√°tico
   - CDN global

---

### Implementaci√≥n

#### Fase 1: Pre-generar Cache (1 d√≠a)
```python
# scripts/generate_common_queries.py

# 1. Identificar 500 preguntas m√°s comunes
common_queries = [
    # Bienestar Animal (100)
    "¬øQu√© es el bienestar animal?",
    "¬øC√≥mo evaluar bienestar animal?",
    "Indicadores de bienestar animal",
    # ... 97 m√°s
    
    # Vacunaci√≥n (80)
    "¬øC√≥mo vacunar ganado?",
    "¬øQu√© vacunas son obligatorias?",
    # ... 78 m√°s
    
    # Transporte (70)
    "¬øC√≥mo preparar animales para transporte?",
    # ... 69 m√°s
    
    # ... 250 m√°s categorizadas
]

# 2. Generar respuestas offline
from src.rag_bpg_ollama import RAGBPGOllama

rag = RAGBPGOllama()
cache = {}

for query in common_queries:
    print(f"Generando: {query}")
    response = rag.query(query)
    cache[query] = {
        "answer": response["answer"],
        "keywords": extract_keywords(query),
        "category": categorize(query)
    }

# 3. Guardar en PWA
import json
with open('pwa/cache.json', 'w') as f:
    json.dump(cache, f, ensure_ascii=False, indent=2)

print(f"‚úÖ {len(cache)} respuestas pre-generadas")
```

#### Fase 2: Modificar PWA (2 horas)
```javascript
// pwa/js/app.js

// Cargar cache al iniciar
let CACHE = {};

async function loadCache() {
    const response = await fetch('cache.json');
    CACHE = await response.json();
    console.log(`‚úÖ ${Object.keys(CACHE).length} respuestas cargadas`);
}

// Mejorar queryOffline
async function queryOffline(query) {
    // 1. Buscar match exacto
    if (CACHE[query]) {
        return {
            answer: CACHE[query].answer,
            source: 'cache-exact',
            cacheNote: 'üì¶ Respuesta pre-cargada'
        };
    }
    
    // 2. Buscar similarity (ya implementado)
    const keywords = extractKeywords(query);
    let bestMatch = null;
    let bestScore = 0;
    
    for (const [cachedQuery, data] of Object.entries(CACHE)) {
        const score = calculateSimilarity(keywords, data.keywords);
        if (score > bestScore && score > 0.3) {
            bestScore = score;
            bestMatch = data;
        }
    }
    
    if (bestMatch) {
        return {
            answer: bestMatch.answer,
            source: 'cache-similar',
            similarity: bestScore,
            cacheNote: `üì¶ Respuesta similar (${Math.round(bestScore*100)}% match)`
        };
    }
    
    // 3. Si no hay match ‚Üí requiere internet
    throw new Error('Consulta no disponible offline. Conecta a WiFi.');
}

// Inicializar
document.addEventListener('DOMContentLoaded', async () => {
    await loadCache();
    // ... resto del c√≥digo
});
```

#### Fase 3: Deploy Frontend (10 min)
```bash
# 1. Build PWA con cache
cd pwa
ls -lh cache.json  # Verificar ~5-10MB

# 2. Deploy a Vercel
npm i -g vercel
vercel --prod

# Resultado: https://bpg-consultas.vercel.app
```

#### Fase 4: Serverless API (30 min)
```python
# api/serverless/query.py (Vercel Function)

from src.rag_bpg_ollama import RAGBPGOllama
import json

# Inicializar RAG (cold start ~5s)
rag = RAGBPGOllama()

def handler(request):
    data = json.loads(request.body)
    query = data.get('query')
    
    # Generar respuesta
    response = rag.query(query)
    
    # TODO: Guardar en cache para pr√≥xima vez
    # save_to_cache(query, response)
    
    return {
        'statusCode': 200,
        'body': json.dumps(response)
    }
```
```json
// vercel.json
{
  "functions": {
    "api/serverless/*.py": {
      "runtime": "python3.9",
      "maxDuration": 60
    }
  }
}
```

#### Fase 5: GPU On-Demand (Opcional)
```python
# Si Vercel serverless es lento:
# Conectar a RunPod GPU via API

import requests

def query_via_runpod(query):
    # Inicia pod si est√° apagado
    pod_id = start_pod_if_needed()
    
    # Consulta
    response = requests.post(
        f'https://{pod_id}.runpod.io/query',
        json={'query': query}
    )
    
    # Apaga despu√©s de 5 min inactividad
    schedule_shutdown(pod_id, delay=300)
    
    return response.json()
```

---

### Flujo Usuario Real

#### Instalaci√≥n (Primera vez):
```
1. Productor abre: bpg-consultas.vercel.app
2. Browser: "Instalar BPG Consultas?" 
3. Click "Instalar"
4. Descarga cache.json (5-10MB, ~30s con 3G)
5. √çcono aparece en pantalla
```

#### Uso en campo (SIN se√±al):
```
Usuario: "¬øC√≥mo vacunar ganado?"
  ‚Üì
App busca en cache local
  ‚Üì Match exacto en 500 pre-generadas
Respuesta instant√°nea (0.1s) ‚úÖ

Usuario: "¬øC√≥mo aplicar vacunas a vacas?"
  ‚Üì
Similarity: 75% match con "¬øC√≥mo vacunar ganado?"
  ‚Üì
Usa respuesta similar (0.1s) ‚úÖ

Usuario: "¬øC√≥mo exportar a China?" (raro)
  ‚Üì
No hay match en cache
  ‚Üì
Error: "Consulta requiere conexi√≥n"
```

#### Uso con WiFi:
```
Usuario: "¬øC√≥mo exportar a China?"
  ‚Üì
Request a Vercel serverless
  ‚Üì
Genera respuesta (10-30s)
  ‚Üì
Guarda en cache local
  ‚Üì
Pr√≥xima vez = offline ‚úÖ
```

---

### Costos Reales

#### Por Escala:

| Usuarios | Consultas/mes | Costo Vercel | Costo GPU | Total/mes |
|----------|---------------|--------------|-----------|-----------|
| 10 | 300 (30 nuevas) | $0 | $1 | **$1** |
| 50 | 1,500 (150 nuevas) | $5 | $5 | **$10** |
| 500 | 15,000 (1,500 nuevas) | $10 | $15 | **$25** |
| 1,000 | 30,000 (3,000 nuevas) | $15 | $20 | **$35** |

**Por usuario:** $0.03-0.05/mes

**Setup inicial:** $0 (todo serverless)

---

### Ventajas vs Alternativas

| Aspecto | H√≠brido | VPS Tradicional |
|---------|---------|-----------------|
| **Costo 50 usuarios** | $10/mes | $50/mes |
| **Offline %** | 90% instant√°neo | Requiere siempre API |
| **Latencia offline** | 0.1s | N/A |
| **Latencia online** | 10-30s | 5-10s |
| **Escalabilidad** | Auto | Manual |
| **Mantenimiento** | 0 horas/mes | 2-4 horas/mes |

---

### M√©tricas Esperadas

**Despu√©s de 1 mes con 50 usuarios:**
- 90% consultas resueltas offline (instant√°neo)
- 10% consultas nuevas (requieren API)
- Cache crece a ~800 respuestas
- Costo: $8-12/mes

**Despu√©s de 6 meses:**
- 95% consultas offline (cache completo)
- Cache: ~1,200 respuestas
- Costo: $10-15/mes (estable)

---

### Limitaciones

1. **Cache inicial:** Descarga 5-10MB (30s con 3G)
2. **Consultas muy raras:** Necesitan internet primera vez
3. **Cold start:** Primera consulta nueva ~10-30s

**Soluciones:**
- Pre-instalar en WiFi antes de ir al campo
- Cache crece con uso ‚Üí cada vez m√°s offline
- Background sync cuando hay WiFi

---

### Recomendaci√≥n Implementaci√≥n

**Para proyecto acad√©mico:**
- ‚úÖ Documentar esta arquitectura
- ‚úÖ Demostrar funcional en local
- ‚úÖ Mencionar como soluci√≥n profesional



---

### Documentaci√≥n T√©cnica

- **Vercel Docs:** https://vercel.com/docs/functions
- **Serverless Python:** https://vercel.com/docs/functions/runtimes/python
- **RunPod API:** https://docs.runpod.io
- **PWA Cache Strategies:** https://web.dev/offline-cookbook/

---



### Expansi√≥n

- [ ] Otras √°reas agr√≠colas (avicultura, porcinos)
- [ ] Integraci√≥n con sistemas de gesti√≥n ganadera
- [ ] App m√≥vil nativa (iOS/Android)

---

## üë§ Autor

**[Gaspar Gonzalez Wulfsohn]**  
**Email:** gaspargw@gmail.com
**LinkedIn:** - 
**GitHub:** GasparGW

**Materia:** Text Mining  
**Profesor:** Hern√°n Merlino
**Fecha entrega:** 3 nov 2025

---

## üìÑ Licencia

MIT License - Ver [LICENSE](LICENSE) para detalles.

---

## üôè Agradecimientos

- Profesor [Nombre] por gu√≠a en Text Mining
- ChromaDB team por excelente documentaci√≥n
- Ollama por democratizar acceso a LLMs
- Comunidad de productores ganaderos por feedback

---

**‚≠ê Si este proyecto te fue √∫til, dale una estrella en GitHub**

