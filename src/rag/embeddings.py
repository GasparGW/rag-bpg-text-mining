import json
from pathlib import Path
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings
from tqdm import tqdm
import numpy as np
import shutil

# Rutas
CHUNKS_FILE = Path("data/processed/chunks.json")
CHROMA_DIR = Path("models/chroma_db")
CHROMA_DIR.mkdir(parents=True, exist_ok=True)

# Configuraci√≥n
EMBEDDING_MODEL = "paraphrase-multilingual-mpnet-base-v2"
COLLECTION_NAME = "bpg_manuals"

def load_chunks():
    """Carga chunks desde JSON"""
    print(f"üìÑ Cargando chunks desde {CHUNKS_FILE}")
    
    if not CHUNKS_FILE.exists():
        raise FileNotFoundError(f"No se encuentra el archivo {CHUNKS_FILE}")
    
    with open(CHUNKS_FILE, 'r', encoding='utf-8') as f:
        chunks = json.load(f)
    
    if not chunks:
        raise ValueError("El archivo de chunks est√° vac√≠o")
    
    print(f"‚úÖ {len(chunks)} chunks cargados\n")
    return chunks

def initialize_embedding_model():
    """Inicializa modelo de embeddings"""
    print(f"üîß Cargando modelo: {EMBEDDING_MODEL}")
    print("   (Primera vez puede tardar - descarga ~420 MB)")
    
    model = SentenceTransformer(EMBEDDING_MODEL)
    embedding_dim = model.get_sentence_embedding_dimension()
    
    print(f"‚úÖ Modelo cargado")
    print(f"   Dimensiones: {embedding_dim}\n")
    
    return model, embedding_dim

def initialize_chromadb(embedding_dim):
    """Inicializa ChromaDB con limpieza completa"""
    print(f"üíæ Inicializando ChromaDB en {CHROMA_DIR}")
    
    # Eliminar directorio completo para evitar problemas de metadata
    if CHROMA_DIR.exists():
        print("   Eliminando base de datos anterior...")
        shutil.rmtree(CHROMA_DIR)
        CHROMA_DIR.mkdir(parents=True, exist_ok=True)
        print("   ‚úì Base de datos anterior eliminada")
    
    client = chromadb.PersistentClient(
        path=str(CHROMA_DIR),
        settings=Settings(anonymized_telemetry=False)
    )
    
    # Crear colecci√≥n nueva con metadata expl√≠cita
    collection = client.create_collection(
        name=COLLECTION_NAME,
        metadata={
            "description": "Manuales BPG vectorizados",
            "hnsw:space": "cosine",
            "embedding_dimension": str(embedding_dim)
        }
    )
    
    print(f"‚úÖ Colecci√≥n '{COLLECTION_NAME}' creada")
    print(f"   Dimensi√≥n configurada: {embedding_dim}\n")
    return collection

def generate_and_store_embeddings(chunks, model, collection):
    """Genera embeddings y los guarda en ChromaDB"""
    print("üî¢ Generando embeddings...")
    
    texts = [chunk['text'] for chunk in chunks]
    chunk_ids = [chunk['chunk_id'] for chunk in chunks]
    
    # Validar que no haya IDs duplicados
    if len(chunk_ids) != len(set(chunk_ids)):
        raise ValueError("Hay chunk_ids duplicados en los datos")
    
    # Generar embeddings en batch (m√°s eficiente)
    embeddings = model.encode(
        texts,
        show_progress_bar=True,
        batch_size=32,
        convert_to_numpy=True
    )
    
    print(f"\n‚úÖ {len(embeddings)} embeddings generados")
    print(f"   Forma: {embeddings.shape}")
    print(f"   Tipo: {type(embeddings)}\n")
    
    # Preparar metadata
    metadatas = []
    for chunk in chunks:
        metadatas.append({
            "source": chunk['source'],
            "chunk_number": chunk['chunk_number'],
            "total_chunks": chunk['total_chunks'],
            "word_count": chunk['word_count']
        })
    
    # Guardar en ChromaDB
    print("üíæ Guardando en ChromaDB...")
    
    collection.add(
        ids=chunk_ids,
        embeddings=embeddings.tolist(),
        documents=texts,
        metadatas=metadatas
    )
    
    stored_count = collection.count()
    print(f"‚úÖ {stored_count} vectores guardados en ChromaDB")
    
    if stored_count != len(chunks):
        print(f"‚ö†Ô∏è  ADVERTENCIA: Se esperaban {len(chunks)} vectores, pero se guardaron {stored_count}")
    print()

def verify_storage(collection, model):
    """Verifica que los datos se guardaron correctamente"""
    print("üîç Verificando almacenamiento...")
    
    # Verificar conteo
    stored_count = collection.count()
    print(f"   Documentos en colecci√≥n: {stored_count}")
    
    if stored_count == 0:
        raise ValueError("La colecci√≥n est√° vac√≠a despu√©s de guardar")
    
    # Generar embedding para la query con el mismo modelo
    query_text = "vacunaci√≥n ganado bovino"
    print(f"   Generando embedding para query de prueba...")
    
    query_embedding = model.encode([query_text], convert_to_numpy=True)
    print(f"   Embedding generado - dimensi√≥n: {query_embedding.shape}")
    
    # Test query usando el embedding generado
    results = collection.query(
        query_embeddings=query_embedding.tolist(),
        n_results=min(3, stored_count)
    )
    
    print(f"\n‚úÖ Verificaci√≥n exitosa")
    print(f"\nüìù Test query: '{query_text}'")
    print(f"   Top {len(results['documents'][0])} chunks recuperados:")
    
    for i, (doc, metadata) in enumerate(zip(results['documents'][0], results['metadatas'][0]), 1):
        print(f"\n   {i}. Fuente: {metadata['source']}")
        print(f"      Chunk: {metadata['chunk_number']}/{metadata['total_chunks']}")
        print(f"      Preview: {doc[:100]}...")

def main():
    """Pipeline principal"""
    print("=" * 60)
    print("üöÄ GENERACI√ìN DE EMBEDDINGS Y ALMACENAMIENTO VECTORIAL")
    print("=" * 60 + "\n")
    
    try:
        # 1. Cargar chunks
        chunks = load_chunks()
        
        # 2. Inicializar modelo embeddings
        model, embedding_dim = initialize_embedding_model()
        
        # 3. Inicializar ChromaDB
        collection = initialize_chromadb(embedding_dim)
        
        # 4. Generar y guardar embeddings
        generate_and_store_embeddings(chunks, model, collection)
        
        # 5. Verificar
        verify_storage(collection, model)
        
        print("\n" + "=" * 60)
        print("üéâ PROCESO COMPLETADO EXITOSAMENTE")
        print("=" * 60)
        print(f"\nüìä Resumen:")
        print(f"   ‚Ä¢ Chunks procesados: {len(chunks)}")
        print(f"   ‚Ä¢ Vectores en ChromaDB: {collection.count()}")
        print(f"   ‚Ä¢ Dimensi√≥n embeddings: {embedding_dim}")
        print(f"   ‚Ä¢ Ubicaci√≥n: {CHROMA_DIR}")
        print(f"   ‚Ä¢ Modelo: {EMBEDDING_MODEL}")
        
    except Exception as e:
        print(f"\n‚ùå ERROR: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())